{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19bfb1b",
   "metadata": {},
   "source": [
    "## Setup\n",
    "- Setup: paths, environment, imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22a9232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DATA_PATH: /Users/munaugas/Desktop/Thesis/adult_reconstruction.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# --- Setup: paths, environment, imports ---\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure src/ is importable even when running from 06_interpretability/\n",
    "repo_root = Path.cwd().resolve().parents[0]\n",
    "src_path = repo_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Set local data path (DO NOT COMMIT dataset)\n",
    "os.environ[\"DATA_PATH\"] = \"/Users/munaugas/Desktop/Thesis/adult_reconstruction.csv\"\n",
    "print(\"Using DATA_PATH:\", os.environ.get(\"DATA_PATH\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shap\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Make sure outputs exist\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "os.makedirs(\"../figures\", exist_ok=True)\n",
    "\n",
    "# Reuse perturbations from robustness stage\n",
    "from thesis_pipeline.robustness.add_noise import add_gaussian_noise\n",
    "from thesis_pipeline.robustness.distribution_shift import apply_simple_shift\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64daeed",
   "metadata": {},
   "source": [
    "## Pipeline and model training\n",
    "- Load data, preprocess, split, and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5bee71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "Models trained: ['RandomForest', 'GBDT', 'XGBoost']\n",
      "X_train: (34671, 13) | X_test: (7430, 13)\n"
     ]
    }
   ],
   "source": [
    "# --- Load data, preprocess, split, and train models (same as baseline/robustness) ---\n",
    "\n",
    "from thesis_pipeline.preprocessing.clean_data import load_data\n",
    "from thesis_pipeline.preprocessing.feature_engineering import engineer_features_and_target\n",
    "from thesis_pipeline.preprocessing.encode_features import encode_features\n",
    "from thesis_pipeline.splitting.split_data import stratified_train_val_test_split\n",
    "\n",
    "from thesis_pipeline.model_training.train_rf import train_random_forest\n",
    "from thesis_pipeline.model_training.train_gbdt import train_gbdt\n",
    "from thesis_pipeline.model_training.train_xgboost import train_xgboost\n",
    "\n",
    "# Load raw data\n",
    "df = load_data()\n",
    "\n",
    "# Feature/target split\n",
    "X_raw, y, df_with_target = engineer_features_and_target(df)\n",
    "\n",
    "# Encoding\n",
    "X, encoder, categorical_cols, numeric_cols = encode_features(X_raw)\n",
    "\n",
    "# Splitting\n",
    "splits_obj = stratified_train_val_test_split(X, y)\n",
    "X_train, y_train = splits_obj.X_train, splits_obj.y_train\n",
    "X_val, y_val     = splits_obj.X_val, splits_obj.y_val\n",
    "X_test, y_test   = splits_obj.X_test, splits_obj.y_test\n",
    "\n",
    "# Training (unpack outputs: model, eval_df, best_params)\n",
    "rf_model, rf_eval, rf_params = train_random_forest(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "gbdt_model, gbdt_eval, gbdt_params = train_gbdt(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "xgb_model, xgb_eval, xgb_params = train_xgboost(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "\n",
    "best_models = {\n",
    "    \"RandomForest\": rf_model,\n",
    "    \"GBDT\": gbdt_model,\n",
    "    \"XGBoost\": xgb_model,\n",
    "}\n",
    "\n",
    "print(\"Models trained:\", list(best_models.keys()))\n",
    "print(\"X_train:\", X_train.shape, \"| X_test:\", X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6affeb5c",
   "metadata": {},
   "source": [
    "## SHAP computation on clean data\n",
    "- Sample data for SHAP computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33830afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP sample sizes:\n",
      "X_train_shap: (1000, 13)\n",
      "X_test_shap: (1000, 13)\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "shap_sample_size = 1000\n",
    "\n",
    "X_train_shap = X_train.sample(n=min(shap_sample_size, len(X_train)), random_state=RANDOM_STATE).copy()\n",
    "X_test_shap  = X_test.sample(n=min(shap_sample_size, len(X_test)),  random_state=RANDOM_STATE).copy()\n",
    "\n",
    "print(\"SHAP sample sizes:\")\n",
    "print(\"X_train_shap:\", X_train_shap.shape)\n",
    "print(\"X_test_shap:\", X_test_shap.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6062ff",
   "metadata": {},
   "source": [
    "- Compute SHAP values (TreeExplainer) and save global summary plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554a0cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SHAP for RandomForest (clean) ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_clean_RandomForest.png\n",
      "\n",
      "=== SHAP for GBDT (clean) ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_clean_GBDT.png\n",
      "\n",
      "=== SHAP for XGBoost (clean) ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_clean_XGBoost.png\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "shap_sample_size = min(1000, len(X_test))\n",
    "\n",
    "X_test_shap = X_test.sample(n=shap_sample_size, random_state=RANDOM_STATE).copy()\n",
    "\n",
    "FIG_DIR = (repo_root / \"figures\")\n",
    "SUBGROUP_FIG_DIR = FIG_DIR / \"subgroup_shap\"\n",
    "SUBGROUP_FIG_DIR.mkdir(exist_ok=True)\n",
    "RES_DIR = (repo_root / \"results\")\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "RES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def safe_name(x: str) -> str:\n",
    "    x = str(x)\n",
    "    x = x.replace(\" \", \"\")\n",
    "    x = x.replace(\"/\", \"_\")\n",
    "    x = x.replace(\"+\", \"plus\")\n",
    "    x = re.sub(r\"[^A-Za-z0-9_\\-\\.]\", \"_\", x)\n",
    "    return x\n",
    "\n",
    "def get_standard_shap_values(explainer, X: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return 2D SHAP values (n_samples, n_features) for positive class.\n",
    "    Also collapses interaction-style outputs to main-effect values.\n",
    "    \"\"\"\n",
    "    shap_vals = explainer.shap_values(X)\n",
    "\n",
    "    # list -> take positive class\n",
    "    if isinstance(shap_vals, list):\n",
    "        shap_vals = shap_vals[1] if len(shap_vals) > 1 else shap_vals[0]\n",
    "\n",
    "    # Explanation -> .values\n",
    "    if hasattr(shap_vals, \"values\"):\n",
    "        shap_vals = shap_vals.values\n",
    "\n",
    "    shap_vals = np.asarray(shap_vals)\n",
    "\n",
    "    # multi-output (n, p, 2) -> take class 1\n",
    "    if shap_vals.ndim == 3 and shap_vals.shape[2] == 2:\n",
    "        shap_vals = shap_vals[:, :, 1]\n",
    "\n",
    "    # interaction (n, p, p) -> collapse\n",
    "    if shap_vals.ndim == 3 and shap_vals.shape[1] == X.shape[1] and shap_vals.shape[2] == X.shape[1]:\n",
    "        shap_vals = shap_vals.sum(axis=2)\n",
    "\n",
    "    if shap_vals.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D SHAP values, got shape {shap_vals.shape}\")\n",
    "\n",
    "    return shap_vals\n",
    "\n",
    "shap_results = {}\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    print(f\"\\n=== SHAP for {model_name} (clean) ===\")\n",
    "\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_2d = get_standard_shap_values(explainer, X_test_shap)\n",
    "\n",
    "    shap_results[model_name] = {\n",
    "        \"explainer\": explainer,\n",
    "        \"shap_values_clean\": shap_2d,\n",
    "        \"X_test_shap\": X_test_shap,\n",
    "    }\n",
    "\n",
    "    shap.summary_plot(shap_2d, X_test_shap, show=False, max_display=10)\n",
    "    plt.title(f\"SHAP Summary Plot - {model_name}\")\n",
    "\n",
    "    outpath = FIG_DIR / f\"shap_summary_clean_{safe_name(model_name)}.png\"\n",
    "    plt.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Saved: {outpath}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8509aac",
   "metadata": {},
   "source": [
    "## Global SHAP importance tables\n",
    "- Export global SHAP importance tables (Top-K + full summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6873441",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: valid expression required before '}' (2981903130.py, line 56)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m} features by mean absolute SHAP value (global importance) for each model on the clean test set.\",\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m f-string: valid expression required before '}'\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# --- Export global SHAP importance + summary tables as CSV + LaTeX ---\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "\n",
    "TOP_K = 10  \n",
    "OUT_DIR = \"../results\"\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def mean_abs_shap_profile(shap_values_2d: np.ndarray, feature_cols) -> pd.Series:\n",
    "    \"\"\"Mean absolute SHAP value per feature.\"\"\"\n",
    "    vals = np.abs(shap_values_2d).mean(axis=0)\n",
    "    return pd.Series(vals, index=list(feature_cols))\n",
    "\n",
    "def to_latex_table(df: pd.DataFrame, out_tex: str, caption: str, label: str):\n",
    "    df.to_latex(\n",
    "        out_tex,\n",
    "        index=False,\n",
    "        float_format=\"%.3f\",\n",
    "        caption=caption,\n",
    "        label=label,\n",
    "        escape=True\n",
    "    )\n",
    "\n",
    "# ---------- 1) shap_global_importance_topk (per model, top-k) ----------\n",
    "rows = []\n",
    "for model_name, info in shap_results.items():\n",
    "    shap_2d = info[\"shap_values_clean\"]          # (n_samples, n_features)\n",
    "    Xs = info[\"X_test_shap\"]                      # dataframe with columns\n",
    "    profile = mean_abs_shap_profile(shap_2d, Xs.columns)\n",
    "\n",
    "    topk = profile.sort_values(ascending=False).head(TOP_K)\n",
    "    for feat, val in topk.items():\n",
    "        rows.append({\n",
    "            \"model\": model_name,\n",
    "            \"feature\": feat,\n",
    "            \"mean_abs_shap\": float(val)\n",
    "        })\n",
    "\n",
    "shap_global_importance_topk = pd.DataFrame(rows)\n",
    "\n",
    "out_csv = f\"{OUT_DIR}/shap_global_importance_topk.csv\"\n",
    "shap_global_importance_topk.to_csv(out_csv, index=False)\n",
    "print(f\"Saved: {out_csv}\")\n",
    "\n",
    "out_tex = f\"{OUT_DIR}/shap_global_importance_topk.tex\"\n",
    "to_latex_table(\n",
    "    shap_global_importance_topk,\n",
    "    out_tex,\n",
    "    caption=f\"Top_K{\n",
    "        \n",
    "    } features by mean absolute SHAP value (global importance) for each model on the clean test set.\",\n",
    "    label=\"tab:shap-global-importance-topk\",\n",
    ")\n",
    "print(f\"Saved: {out_tex}\")\n",
    "\n",
    "\n",
    "# ---------- 2) shap_summary_table (all features, aggregated per model) ----------\n",
    "# This produces a compact table where each feature is a row and each model is a column.\n",
    "# Values are mean(|SHAP|) so it reads as \"global importance\".\n",
    "\n",
    "summary_frames = []\n",
    "for model_name, info in shap_results.items():\n",
    "    shap_2d = info[\"shap_values_clean\"]\n",
    "    Xs = info[\"X_test_shap\"]\n",
    "    profile = mean_abs_shap_profile(shap_2d, Xs.columns).rename(model_name)\n",
    "    summary_frames.append(profile)\n",
    "\n",
    "shap_summary_table = pd.concat(summary_frames, axis=1).reset_index().rename(columns={\"index\": \"feature\"})\n",
    "\n",
    "# Optional: also add an \"avg_across_models\" column to rank features overall\n",
    "model_cols = [c for c in shap_summary_table.columns if c != \"feature\"]\n",
    "shap_summary_table[\"avg_across_models\"] = shap_summary_table[model_cols].mean(axis=1)\n",
    "\n",
    "# Sort by overall average importance (descending)\n",
    "shap_summary_table = shap_summary_table.sort_values(\"avg_across_models\", ascending=False)\n",
    "\n",
    "# Save CSV\n",
    "out_csv = f\"{OUT_DIR}/shap_summary_table.csv\"\n",
    "shap_summary_table.to_csv(out_csv, index=False)\n",
    "print(f\"Saved: {out_csv}\")\n",
    "\n",
    "# Save LaTeX (rounded visually via float_format)\n",
    "out_tex = f\"{OUT_DIR}/shap_summary_table.tex\"\n",
    "to_latex_table(\n",
    "    shap_summary_table,\n",
    "    out_tex,\n",
    "    caption=\"Global SHAP importance table (mean absolute SHAP values per feature).\",\n",
    "    label=\"tab:shap-summary-table\",\n",
    ")\n",
    "print(f\"Saved: {out_tex}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89489807",
   "metadata": {},
   "source": [
    "## Subgroup setup\n",
    "- Build subgroup metadata (gender, race_binary, age_group) (same as LIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84dafda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>race_binary</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21460</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>21</td>\n",
       "      <td>White</td>\n",
       "      <td>18-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>Male</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>51</td>\n",
       "      <td>Non-White</td>\n",
       "      <td>46-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>34</td>\n",
       "      <td>White</td>\n",
       "      <td>31-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22480</th>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>26</td>\n",
       "      <td>White</td>\n",
       "      <td>18-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47104</th>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>28</td>\n",
       "      <td>White</td>\n",
       "      <td>18-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender                race  age race_binary age_group\n",
       "21460    Male               White   21       White     18-30\n",
       "35060    Male  Amer-Indian-Eskimo   51   Non-White     46-60\n",
       "1633     Male               White   34       White     31-45\n",
       "22480  Female               White   26       White     18-30\n",
       "47104  Female               White   28       White     18-30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build subgroup metadata using original rows corresponding to X_test indices\n",
    "meta_test = df_with_target.loc[X_test.index, [\"gender\", \"race\", \"age\"]].copy()\n",
    "\n",
    "# Race: White vs Non-White\n",
    "meta_test[\"race_binary\"] = np.where(meta_test[\"race\"] == \"White\", \"White\", \"Non-White\")\n",
    "\n",
    "# Age groups as in thesis / Colab\n",
    "age_bins   = [17, 30, 45, 60, 90]\n",
    "age_labels = [\"18-30\", \"31-45\", \"46-60\", \"61+\"]\n",
    "meta_test[\"age_group\"] = pd.cut(meta_test[\"age\"], bins=age_bins, labels=age_labels)\n",
    "\n",
    "meta_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a92ee7",
   "metadata": {},
   "source": [
    "## Subgroup SHAP explanations\n",
    "- Generate subgroup SHAP summary plots (by gender, race, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b6085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SHAP by gender for RandomForest ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_gender_Male_RandomForest.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_gender_Female_RandomForest.png\n",
      "\n",
      "=== SHAP by race_binary for RandomForest ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_race_binary_White_RandomForest.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_race_binary_Non-White_RandomForest.png\n",
      "\n",
      "=== SHAP by age_group for RandomForest ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_18-30_RandomForest.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_46-60_RandomForest.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_31-45_RandomForest.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_61plus_RandomForest.png\n",
      "\n",
      "=== SHAP by gender for GBDT ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_gender_Male_GBDT.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_gender_Female_GBDT.png\n",
      "\n",
      "=== SHAP by race_binary for GBDT ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_race_binary_White_GBDT.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_race_binary_Non-White_GBDT.png\n",
      "\n",
      "=== SHAP by age_group for GBDT ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_18-30_GBDT.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_46-60_GBDT.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_31-45_GBDT.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_61plus_GBDT.png\n",
      "\n",
      "=== SHAP by gender for XGBoost ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_gender_Male_XGBoost.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_gender_Female_XGBoost.png\n",
      "\n",
      "=== SHAP by race_binary for XGBoost ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_race_binary_White_XGBoost.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_race_binary_Non-White_XGBoost.png\n",
      "\n",
      "=== SHAP by age_group for XGBoost ===\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_18-30_XGBoost.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_46-60_XGBoost.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_31-45_XGBoost.png\n",
      "Saved: /Users/munaugas/MSc_Data_Science_Thesis/MSc_Data_Science_Thesis/figures/shap_summary_age_group_61plus_XGBoost.png\n"
     ]
    }
   ],
   "source": [
    "def plot_and_save_shap_summary_by_subgroup(\n",
    "    model_name: str,\n",
    "    group_col: str,\n",
    "    *,\n",
    "    max_display: int = 10,\n",
    "    min_group_size: int = 50\n",
    "):\n",
    "    info = shap_results[model_name]\n",
    "    shap_values = info[\"shap_values_clean\"]   # guaranteed 2D from helper\n",
    "    Xs = info[\"X_test_shap\"]\n",
    "\n",
    "    groups = meta_test.loc[Xs.index, group_col]\n",
    "\n",
    "    print(f\"\\n=== SHAP by {group_col} for {model_name} ===\")\n",
    "    for group_value in groups.dropna().unique():\n",
    "        mask = (groups == group_value)\n",
    "        n = int(mask.sum())\n",
    "        if n < min_group_size:\n",
    "            print(f\"Skipping {group_col}={group_value} (n={n})\")\n",
    "            continue\n",
    "\n",
    "        shap.summary_plot(\n",
    "            shap_values[mask.values],\n",
    "            Xs.loc[mask],\n",
    "            max_display=max_display,\n",
    "            show=False\n",
    "        )\n",
    "        plt.title(f\"{model_name} - SHAP ({group_col}={group_value})\")\n",
    "\n",
    "        fname = f\"shap_summary_{safe_name(group_col)}_{safe_name(group_value)}_{safe_name(model_name)}.png\"\n",
    "        outpath = SUBGROUP_FIG_DIR / fname\n",
    "\n",
    "        plt.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(f\"Saved: {outpath}\")\n",
    "\n",
    "for model_name in best_models.keys():\n",
    "    for group_col in [\"gender\", \"race_binary\", \"age_group\"]:\n",
    "        plot_and_save_shap_summary_by_subgroup(model_name, group_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca80de",
   "metadata": {},
   "source": [
    "- Export subgroup SHAP importance table (Top-K mean(|SHAP|))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d92f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../results/shap_subgroup_importance_topk.csv\n",
      "Saved: ../results/shap_subgroup_importance_topk.tex\n",
      "CSV Top-K = 10 | LaTeX Top-K = 3\n"
     ]
    }
   ],
   "source": [
    "# --- Export subgroup mean(|SHAP|) importance (Top-K) as CSV + LaTeX ---\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "\n",
    "TOP_K_CSV = 10   # keep more detail in CSV\n",
    "TOP_K_TEX = 3    # keep appendix short\n",
    "MIN_GROUP_SIZE = 50\n",
    "group_cols = [\"gender\", \"race_binary\", \"age_group\"]\n",
    "\n",
    "def mean_abs_shap_profile(shap_values_2d: np.ndarray, feature_cols) -> pd.Series:\n",
    "    vals = np.abs(shap_values_2d).mean(axis=0)\n",
    "    return pd.Series(vals, index=list(feature_cols))\n",
    "\n",
    "rows_csv = []\n",
    "rows_tex = []\n",
    "\n",
    "for model_name, info in shap_results.items():\n",
    "    shap_2d = info[\"shap_values_clean\"]   # (n_samples, n_features)\n",
    "    Xs      = info[\"X_test_shap\"]         # SHAP subset\n",
    "\n",
    "    for group_col in group_cols:\n",
    "        groups = meta_test.loc[Xs.index, group_col]\n",
    "\n",
    "        for group_value in groups.dropna().unique():\n",
    "            mask = (groups == group_value)\n",
    "            n = int(mask.sum())\n",
    "            if n < MIN_GROUP_SIZE:\n",
    "                continue\n",
    "\n",
    "            prof = mean_abs_shap_profile(shap_2d[mask.values], Xs.columns).sort_values(ascending=False)\n",
    "\n",
    "            # --- CSV rows (Top_K_CSV) ---\n",
    "            topk_csv = prof.head(TOP_K_CSV)\n",
    "            for rank, (feat, val) in enumerate(topk_csv.items(), start=1):\n",
    "                rows_csv.append({\n",
    "                    \"model\": model_name,\n",
    "                    \"group_col\": group_col,\n",
    "                    \"group_value\": str(group_value),\n",
    "                    \"n_samples\": n,\n",
    "                    \"rank\": rank,\n",
    "                    \"feature\": feat,\n",
    "                    \"mean_abs_shap\": float(val),\n",
    "                })\n",
    "\n",
    "            # --- LaTeX rows (Top_K_TEX) ---\n",
    "            topk_tex = prof.head(TOP_K_TEX)\n",
    "            for rank, (feat, val) in enumerate(topk_tex.items(), start=1):\n",
    "                rows_tex.append({\n",
    "                    \"model\": model_name,\n",
    "                    \"group_col\": group_col,\n",
    "                    \"group_value\": str(group_value),\n",
    "                    \"n_samples\": n,\n",
    "                    \"rank\": rank,\n",
    "                    \"feature\": feat,\n",
    "                    \"mean_abs_shap\": float(val),\n",
    "                })\n",
    "\n",
    "# --- Save CSV (Top_K_CSV) ---\n",
    "shap_subgroup_importance_topk_csv = pd.DataFrame(rows_csv)\n",
    "out_csv = \"../results/shap_subgroup_importance_topk.csv\"\n",
    "shap_subgroup_importance_topk_csv.to_csv(out_csv, index=False)\n",
    "print(f\"Saved: {out_csv}\")\n",
    "\n",
    "# --- Save LaTeX (Top_K_TEX) ---\n",
    "shap_subgroup_importance_topk_tex = pd.DataFrame(rows_tex)\n",
    "shap_subgroup_importance_topk_tex[\"mean_abs_shap\"] = shap_subgroup_importance_topk_tex[\"mean_abs_shap\"].round(3)\n",
    "\n",
    "out_tex = \"../results/shap_subgroup_importance_topk.tex\"\n",
    "shap_subgroup_importance_topk_tex.to_latex(\n",
    "    out_tex,\n",
    "    longtable=True,\n",
    "    index=False,\n",
    "    float_format=\"%.3f\",\n",
    "    caption=f\"Top-{TOP_K_TEX} subgroup SHAP importance by mean absolute SHAP value (clean test set).\",\n",
    "    label=\"tab:shap-subgroup-importance-topk\",\n",
    "    escape=True,\n",
    ")\n",
    "print(f\"Saved: {out_tex}\")\n",
    "\n",
    "print(f\"CSV Top-K = {TOP_K_CSV} | LaTeX Top-K = {TOP_K_TEX}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cd87e",
   "metadata": {},
   "source": [
    "## SHAP robustness evaluation\n",
    "- Robustness design: mean(|SHAP|) profiles and stability metrics \n",
    "(helpers: mean_abs_shap_profile, shap_stability_metrics)\n",
    "\n",
    "- Compute SHAP robustness under noise and distribution shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1510b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_2d_shap(shap_values):\n",
    "    \"\"\"\n",
    "    Convert SHAP output to a 2D numpy array: (n_samples, n_features).\n",
    "\n",
    "    Handles:\n",
    "    - list output (older SHAP): [class0, class1]\n",
    "    - 3D output (n_samples, n_features, n_classes)\n",
    "    - already-2D output\n",
    "    \"\"\"\n",
    "    if isinstance(shap_values, list):\n",
    "        # binary classification: take class 1 (positive class)\n",
    "        shap_values = shap_values[1]\n",
    "\n",
    "    shap_values = np.asarray(shap_values)\n",
    "\n",
    "    if shap_values.ndim == 3:\n",
    "        # shape: (n_samples, n_features, n_classes) -> take positive class\n",
    "        shap_values = shap_values[:, :, 1]\n",
    "\n",
    "    if shap_values.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D SHAP array, got shape {shap_values.shape}\")\n",
    "\n",
    "    return shap_values\n",
    "\n",
    "\n",
    "def mean_abs_shap_profile(shap_values_2d: np.ndarray, feature_cols) -> pd.Series:\n",
    "    \"\"\"Mean absolute SHAP value per feature (global importance profile).\"\"\"\n",
    "    vals = np.abs(shap_values_2d).mean(axis=0)\n",
    "    return pd.Series(vals, index=list(feature_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c76649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SHAP robustness for RandomForest ===\n",
      "\n",
      "=== SHAP robustness for GBDT ===\n",
      "\n",
      "=== SHAP robustness for XGBoost ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>spearman_rank_corr</th>\n",
       "      <th>l1_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gauss_sigma_0.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gauss_sigma_0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>gauss_sigma_1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>shifted</td>\n",
       "      <td>0.994505</td>\n",
       "      <td>0.038278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>gauss_sigma_0.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>gauss_sigma_0.5</td>\n",
       "      <td>0.994505</td>\n",
       "      <td>0.006119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>gauss_sigma_1.0</td>\n",
       "      <td>0.994505</td>\n",
       "      <td>0.013553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>shifted</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.078162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>gauss_sigma_0.1</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.036117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>gauss_sigma_0.5</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.036389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>gauss_sigma_1.0</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.038337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>shifted</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.119952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model        condition  spearman_rank_corr  l1_distance\n",
       "0   RandomForest  gauss_sigma_0.1            1.000000     0.000969\n",
       "1   RandomForest  gauss_sigma_0.5            1.000000     0.010143\n",
       "2   RandomForest  gauss_sigma_1.0            1.000000     0.018930\n",
       "3   RandomForest          shifted            0.994505     0.038278\n",
       "4           GBDT  gauss_sigma_0.1            1.000000     0.000000\n",
       "5           GBDT  gauss_sigma_0.5            0.994505     0.006119\n",
       "6           GBDT  gauss_sigma_1.0            0.994505     0.013553\n",
       "7           GBDT          shifted            0.978022     0.078162\n",
       "8        XGBoost  gauss_sigma_0.1            0.989011     0.036117\n",
       "9        XGBoost  gauss_sigma_0.5            0.989011     0.036389\n",
       "10       XGBoost  gauss_sigma_1.0            0.989011     0.038337\n",
       "11       XGBoost          shifted            0.961538     0.119952"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "noise_sigmas = [0.1, 0.5, 1.0]\n",
    "rows = []\n",
    "\n",
    "def shap_stability_metrics(clean_profile: pd.Series, pert_profile: pd.Series):\n",
    "    clean_profile = clean_profile.sort_index()\n",
    "    pert_profile  = pert_profile.sort_index()\n",
    "\n",
    "    rho, _ = spearmanr(clean_profile.values, pert_profile.values)\n",
    "\n",
    "    c = clean_profile / (clean_profile.sum() + 1e-12)\n",
    "    p = pert_profile  / (pert_profile.sum()  + 1e-12)\n",
    "    l1 = float(np.abs(c - p).sum())\n",
    "    return float(rho), l1\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    print(f\"\\n=== SHAP robustness for {model_name} ===\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "\n",
    "    shap_clean_2d = get_standard_shap_values(explainer, X_test_shap)\n",
    "    clean_profile = mean_abs_shap_profile(shap_clean_2d, X_test_shap.columns)\n",
    "\n",
    "    # Noise\n",
    "    for sigma in noise_sigmas:\n",
    "        X_noisy = add_gaussian_noise(X_test_shap, numeric_cols, sigma=sigma, random_state=RANDOM_STATE)\n",
    "        shap_noisy_2d = get_standard_shap_values(explainer, X_noisy)\n",
    "        noisy_profile = mean_abs_shap_profile(shap_noisy_2d, X_test_shap.columns)\n",
    "\n",
    "        rho, l1 = shap_stability_metrics(clean_profile, noisy_profile)\n",
    "        rows.append({\n",
    "            \"model\": model_name,\n",
    "            \"condition\": f\"gauss_sigma_{sigma}\",\n",
    "            \"spearman_rank_corr\": rho,\n",
    "            \"l1_distance\": l1,\n",
    "        })\n",
    "\n",
    "    # Shift\n",
    "    X_shifted = apply_simple_shift(X_test_shap, numeric_cols)\n",
    "    shap_shift_2d = get_standard_shap_values(explainer, X_shifted)\n",
    "    shift_profile = mean_abs_shap_profile(shap_shift_2d, X_test_shap.columns)\n",
    "\n",
    "    rho, l1 = shap_stability_metrics(clean_profile, shift_profile)\n",
    "    rows.append({\n",
    "        \"model\": model_name,\n",
    "        \"condition\": \"shifted\",\n",
    "        \"spearman_rank_corr\": rho,\n",
    "        \"l1_distance\": l1,\n",
    "    })\n",
    "\n",
    "shap_robustness_df = pd.DataFrame(rows)\n",
    "shap_robustness_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602db062",
   "metadata": {},
   "source": [
    "- Save SHAP robustness results (CSV + figures + LaTeX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../results/shap_robustness_summary.csv\n",
      "Saved: ../figures/shap_robustness_spearman.png\n",
      "Saved: ../figures/shap_robustness_l1.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "os.makedirs(\"../figures\", exist_ok=True)\n",
    "\n",
    "# Save table referenced in Results\n",
    "out_csv = \"../results/shap_robustness_summary.csv\"\n",
    "shap_robustness_df.to_csv(out_csv, index=False)\n",
    "print(f\"Saved: {out_csv}\")\n",
    "\n",
    "# Order conditions for nicer plots\n",
    "condition_order = [\"gauss_sigma_0.1\", \"gauss_sigma_0.5\", \"gauss_sigma_1.0\", \"shifted\"]\n",
    "shap_robustness_df[\"condition\"] = pd.Categorical(\n",
    "    shap_robustness_df[\"condition\"],\n",
    "    categories=condition_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "df_plot = shap_robustness_df.sort_values([\"model\", \"condition\"]).copy()\n",
    "\n",
    "# Plot Spearman rank correlation\n",
    "plt.figure()\n",
    "for model in df_plot[\"model\"].unique():\n",
    "    sub = df_plot[df_plot[\"model\"] == model].sort_values(\"condition\")\n",
    "    plt.plot(sub[\"condition\"].astype(str), sub[\"spearman_rank_corr\"], marker=\"o\", label=model)\n",
    "\n",
    "plt.ylabel(\"Spearman rank correlation\")\n",
    "plt.title(\"SHAP robustness: feature ranking stability\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.legend()\n",
    "\n",
    "out_fig = \"../figures/shap_robustness_spearman.png\"\n",
    "plt.savefig(out_fig, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Saved: {out_fig}\")\n",
    "\n",
    "# Plot L1 distance\n",
    "plt.figure()\n",
    "for model in df_plot[\"model\"].unique():\n",
    "    sub = df_plot[df_plot[\"model\"] == model].sort_values(\"condition\")\n",
    "    plt.plot(sub[\"condition\"].astype(str), sub[\"l1_distance\"], marker=\"o\", label=model)\n",
    "\n",
    "plt.ylabel(\"L1 distance (normalised profiles)\")\n",
    "plt.title(\"SHAP robustness: attribution magnitude change\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.legend()\n",
    "\n",
    "out_fig = \"../figures/shap_robustness_l1.png\"\n",
    "plt.savefig(out_fig, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Saved: {out_fig}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b1c671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../results/shap_robustness_summary.tex\n"
     ]
    }
   ],
   "source": [
    "# Export SHAP robustness results (.csv -> .tex) for Overleaf\n",
    "\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "\n",
    "shap_fmt = shap_robustness_df.copy()\n",
    "\n",
    "# Round numeric columns to 3 decimals\n",
    "num_cols = [\"spearman_rank_corr\", \"l1_distance\"]\n",
    "shap_fmt[num_cols] = shap_fmt[num_cols].round(3)\n",
    "\n",
    "out_tex = \"../results/shap_robustness_summary.tex\"\n",
    "\n",
    "shap_fmt.to_latex(\n",
    "    out_tex,\n",
    "    index=False,\n",
    "    caption=\"SHAP robustness summary under Gaussian noise and a structured distribution shift.\",\n",
    "    label=\"tab:shap-robustness\",\n",
    "    float_format=\"%.3f\",\n",
    "    escape=True,   # keep safe for underscores, etc.\n",
    ")\n",
    "\n",
    "print(f\"Saved: {out_tex}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
